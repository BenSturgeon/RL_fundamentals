{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "\n",
    "import torch as T\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box([-1.5       -1.5       -5.        -5.        -3.1415927 -5.\n",
      " -0.        -0.       ], [1.5       1.5       5.        5.        3.1415927 5.        1.\n",
      " 1.       ], (8,), float32)\n",
      "action space: Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "# print gym environment information\n",
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    continuous = False,\n",
    "    gravity = -10.0,\n",
    "    enable_wind = False,\n",
    "    wind_power = 15.0,\n",
    "    turbulence_power = 1.5,\n",
    "    render_mode=\"rgb_array\"\n",
    ")\n",
    "print('observation space:', env.observation_space)\n",
    "print('action space:', env.action_space)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gymlibrary.dev/environments/box2d/lunar_lander/\n",
    "\n",
    "## Planning:\n",
    "The goal is to use DQN to solve the lunar lander problem.\n",
    "\n",
    "Currently I am unclear on the following:\n",
    "Exactly how to set up the network to receive inputs and outputs from the system\n",
    "What kind of loss function should be used in this setup to make sure that it is learning correctly.\n",
    "How to account for the various kinds of things can be observed in the observation space.\n",
    "\n",
    "## approach\n",
    "A good first step would be to try and experiment with basic approaches messing around with the system to get a grasp of it.\n",
    "Then I'd like to experiment with a basic neural network feeding in maybe 2 of the parameters.\n",
    "\n",
    "Edit: I think I will try to use the 4 parameters as inputs to the network and see how that goes.\n",
    "Playing with the network structure and the loss function should be the next step.\n",
    "Messing around trying to solve it by hand will probably not be very useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(images):\n",
    "    fig = plt.figure()\n",
    "    ims = []\n",
    "\n",
    "    for image in images:\n",
    "        im = plt.imshow(image, animated=True);\n",
    "        ims.append([im])\n",
    "    plt.close()\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000);\n",
    "\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reset environment\n",
    "state = env.reset()\n",
    "done = False\n",
    "images = []\n",
    "count = 0\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    count +=1\n",
    "    # render environment\n",
    "    image = env.render()\n",
    "    images.append(image)\n",
    "    # sample random action\n",
    "    action = env.action_space.sample()\n",
    "    # take action\n",
    "    observation, state, reward, done, info = env.step(action)\n",
    "    total_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.module):\n",
    "    def __init__(self, input_dims, fc1_dims=64, fc2_dims=64, n_actions=4, alpha=0.0001):\n",
    "        super(network, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dims, fc1_dims)\n",
    "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
    "        self.pi = nn.Linear(fc2_dims, n_actions)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    " \n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        pi = T.softmax(self.pi(x), dim=1)\n",
    "\n",
    "        return pi\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.chkpt_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.chkpt_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd21a57e4fd92262eb0452f059baab566dea59e951fa62645d98860e4237e4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
